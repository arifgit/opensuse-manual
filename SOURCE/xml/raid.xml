<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE sect1 PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd">
<!--
*********************************
Please see LICENSE.txt for this document's license.
*********************************
-->
<sect1 xml:base="raid.xml" id="sec.yast2.system.raid">
 <title>Soft RAID Configuration</title><indexterm>

 <primary>YaST</primary>

 <secondary>RAID</secondary></indexterm><indexterm>

 <primary>RAID</primary>

 <secondary>YaST</secondary></indexterm><indexterm>

 <primary>soft RAID</primary>

 <see>RAID</see></indexterm>



 <para>
  The purpose of RAID (redundant array of independent disks) is to combine
  several hard disk partitions into one large <emphasis>virtual</emphasis>
  hard disk to optimize performance and/or data security. Most RAID
  controllers use the SCSI protocol because it can address a larger number
  of hard disks in a more effective way than the IDE protocol. It is also
  more suitable for the parallel command processing. There are some RAID
  controllers that support IDE or SATA hard disks. Soft RAID provides the
  advantages of RAID systems without the additional cost of hardware RAID
  controllers. However, this requires some CPU time and has memory
  requirements that make it unsuitable for high performance computers.
 </para>

 <para>
  With <phrase os="osuse">openSUSE®</phrase> , you can combine several hard disks into one soft
  RAID system. RAID implies several strategies for combining several hard
  disks in a RAID system, each with different goals, advantages, and
  characteristics. These variations are commonly known as <emphasis>RAID
  levels</emphasis>.
 </para>

 <para>
  Common RAID levels are:
 </para>

 <variablelist>
  <varlistentry>
   <term>RAID 0</term>
   <listitem>
    <para>
     This level improves the performance of your data access by spreading
     out blocks of each file across multiple disk drives. Actually, this is
     not really a RAID, because it does not provide data backup, but the
     name <emphasis>RAID 0</emphasis> for this type of system is
     commonly used. With RAID 0, two or more hard disks are pooled
     together. Performance is enhanced, but the RAID system is destroyed and
     your data lost if even one hard disk fails.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>RAID 1</term>
   <listitem>
    <para>
     This level provides adequate security for your data, because the data
     is copied to another hard disk 1:1. This is known as <emphasis>hard
     disk mirroring</emphasis>. If one disk is destroyed, a copy of its
     contents is available on the other one. All disks but one could be
     damaged without endangering your data. However, if the damage is not
     detected, the damaged data can be mirrored to the undamaged disk. This
     could result in the same loss of data. The writing performance suffers
     in the copying process compared to using single disk access (10 to 20 %
     slower), but read access is significantly faster in comparison to any
     one of the normal physical hard disks. The reason is that the duplicate
     data can be parallel-scanned. Generally it can be said that
     Level 1 provides nearly twice the read transfer rate of single
     disks and almost the same write transfer rate as single disks.
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
   <term>RAID 5</term>
   <listitem>
    <para>
     RAID 5 is an optimized compromise between Level 0 and
     Level 1, in terms of performance and redundancy. The hard disk
     space equals the number of disks used minus one. The data is
     distributed over the hard disks as with RAID 0. <emphasis>Parity
     blocks</emphasis>, created on one of the partitions, exist for security
     reasons. They are linked to each other with XOR, enabling the contents
     to be reconstructed by the corresponding parity block in case of system
     failure. With RAID 5, no more than one hard disk can fail at the
     same time. If one hard disk fails, it must be replaced as soon as
     possible to avoid the risk of losing data.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>RAID 6</term>
   <listitem>
    <para>
     To further increase the reliability of the RAID system, it is possible
     to use RAID 6. In this level, even if two disks fail, the array
     still can be reconstructed. With RAID 6, at least 4 hard disks are
     needed to run the array. Note that when running as software raid, this
     configuration needs a considerable amount of CPU time and memory.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>RAID 10 (RAID 1+0)</term>
   <listitem>
    <para>
     This RAID implementation combines features of RAID 0 and
     RAID 1: the data are first mirrored in separate disk arrays, which
     are inserted into a new RAID 0; type array. In each RAID 1
     sub-array, one disk can fail without any damage to the data.
     RAID 10 is used for database application where a huge load is
     expected.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>Other RAID Levels</term>
   <listitem>
    <para>
     Several other RAID levels have been developed (RAID 2,
     RAID 3, RAID 4, RAIDn, RAID 10, RAID 0+1,
     RAID 30, RAID 50, etc.), some of them being proprietary
     implementations created by hardware vendors. These levels are not very
     common and therefore are not explained here.
    </para>
   </listitem>
  </varlistentry>
 </variablelist>

 <sect2 id="sec.yast2.system.raid.conf">
  <title>Soft RAID Configuration with YaST</title>
  <para>
   The YaST <guimenu>RAID</guimenu> configuration can be reached from the
   YaST Expert Partitioner, described in
   <xref linkend="sec.yast2.i_y2_part_expert"/>. This partitioning tool
   enables you to edit and delete existing partitions and create new ones to
   be used with soft RAID:
  </para>
  <procedure>
   <step performance="required">
    <para>
     Select a hard disk from <guimenu>Hard Disks</guimenu>.
    </para>
   </step>
   <step performance="required">
    <para>
     Change to the <guimenu>Partitions</guimenu> tab.
    </para>
   </step>
   <step performance="required">
    <para>
     Click <guimenu>Add</guimenu> and enter the desired size of the raid
     partition on this disk.
    </para>
   </step>
   <step performance="required">
    <para>
     Use <guimenu>Do not Format the Partition</guimenu> and change the
     <guimenu>File System ID</guimenu> to <guimenu>0xFD Linux
     RAID</guimenu>. Do not mount this partition.
    </para>
   </step>
   <step performance="required">
    <para>
     Repeat this procedure until you have defined all the desired physical
     volumes on the available disks.
    </para>
   </step>
  </procedure>
  <para>
   For RAID 0 and RAID 1, at least two partitions are
   needed—for RAID 1, usually exactly two and no more. If
   RAID 5 is used, at least three partitions are required. It is
   recommended to utilize partitions of the same size only. The RAID
   partitions should be located on different hard disks to decrease the risk
   of losing data if one is defective (RAID 1 and 5) and to optimize
   the performance of RAID 0. After creating all the partitions to use
   with RAID, click <menuchoice><guimenu>RAID</guimenu><guimenu>Add
   RAID</guimenu></menuchoice> to start the RAID configuration.
  </para>
  <para>
   In the next dialog, choose between RAID levels 0, 1, 5, 6 and 10. Then,
   select all partitions with either the <quote>Linux RAID</quote> or
   <quote>Linux native</quote> type that should be used by the RAID system.
   No swap or DOS partitions are shown.
  </para>
  <figure id="fig.yast2.system.raid.conf">
   <title>RAID Partitions</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="yast2_raid4.png" width="75%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="yast2_raid4.png" width="75%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>
  <para>
   To add a previously unassigned partition to the selected RAID volume,
   first click the partition then <guimenu>Add</guimenu>. Assign all
   partitions reserved for RAID. Otherwise, the space on the partition
   remains unused. After assigning all partitions, click
   <guimenu>Next</guimenu> to select the available <guimenu>RAID
   Options</guimenu>.
  </para>
  <para>
   In this last step, set the file system to use as well as encryption and
   the mount point for the RAID volume. After completing the configuration
   with <guimenu>Finish</guimenu>, see the <filename>/dev/md0</filename>
   device and others indicated with <emphasis>RAID</emphasis> in the expert
   partitioner.
  </para>
 </sect2>

 <sect2>
  <title>Troubleshooting</title>
  <para>
   Check the file <filename>/proc/mdstat</filename> to find out whether a
   RAID partition has been damaged. In the event of a system failure, shut
   down your Linux system and replace the defective hard disk with a new one
   partitioned the same way. Then restart your system and enter the command
   <command>mdadm /dev/mdX --add /dev/sdX</command>. Replace 'X' with your
   particular device identifiers. This integrates the hard disk
   automatically into the RAID system and fully reconstructs it.
  </para>
  <para>
   Note that although you can access all data during the rebuild, you may
   encounter some performance issues until the RAID has been fully rebuilt.
  </para>
 </sect2>

<?dbfo-need height="10em"?>


 <sect2>
  <title>For More Information</title>
  <para>
   Configuration instructions and more details for soft RAID can be found in
   the HOWTOs at:
  </para>
  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <filename>/usr/share/doc/packages/mdadm/Software-RAID.HOWTO.html</filename>
    </para>
   </listitem>
   <listitem>
    <para>
     <ulink url="http://raid.wiki.kernel.org"/>
    </para>
   </listitem>
  </itemizedlist>
  <para>
   Linux RAID mailing lists are available, such as
   <ulink url="http://marc.info/?l=linux-raid"/>.
  </para>
 </sect2>
</sect1>
